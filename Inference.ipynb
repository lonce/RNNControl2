{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87851c1e-86fc-4179-8ba1-614bfa31c358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import argparse\n",
    "import soundfile as sf\n",
    "from IPython.display import Audio\n",
    "import time\n",
    "from pathlib import Path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d61fb5-2787-4ecb-8ccb-a0615422f931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local imports from your project structure\n",
    "from model.gru_audio_model import RNN, GRUAudioConfig\n",
    "from utils.utils import multi_linspace, steps, plot_condition_tensor\n",
    "\n",
    "from inference import run_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2eae26-053c-4b32-ba24-4825fa085ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point run dir to the folder that Train.ipynb created for its run.\n",
    "\n",
    "# good one ... run_directory = str(Path('./output/20250811_135640')) # 'Path to the directory of the saved run.'\n",
    "run_directory = str(Path('./output/20250812_122547')) # 'Path to the directory of the saved run.'\n",
    "\n",
    "top_n = 3 #'Sample from the top N most likely outputs.'\n",
    "temperature =.75 #'Controls the randomness of predictions.'\n",
    "length_seconds =4.0 #'Length of the audio to generate in seconds.'\n",
    "\n",
    "sample_rate = 16000\n",
    "generation_length = int(length_seconds * sample_rate)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9df5d7-a54b-40a9-bed3-13e2ce9a9558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------     Load model     -----------#\n",
    "\n",
    "config_path = os.path.join(run_directory, \"config.pt\")\n",
    "checkpoint_path = os.path.join(run_directory, \"checkpoints\", \"last_checkpoint.pt\") # \"checkpoint_40.pt\") # \n",
    "\n",
    "assert os.path.exists(run_directory), f\"Run directory not found: {run_directory}\"\n",
    "assert os.path.exists(config_path), f\"Config file not found: {config_path}\"\n",
    "assert os.path.exists(checkpoint_path), f\"Checkpoint file not found: {checkpoint_path}\"\n",
    "\n",
    "saved_configs = torch.load(config_path, weights_only=False)\n",
    "model_config = saved_configs[\"model_config\"]\n",
    "\n",
    "model = RNN(model_config).to(device)\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model.eval()\n",
    "\n",
    "print(\"Model successfully loaded from checkpoint.\")\n",
    "print(f\"Using device = {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8d0570-d3a7-4abb-b895-c989c613f39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_cond_params = model_config.cond_size\n",
    "cond_seq = torch.zeros(generation_length, num_cond_params)\n",
    "\n",
    "# instID\n",
    "cond_seq[:, 0] = 1  # 0 - clarinet, 1 - trumpet\n",
    "#cond_seq[:, 0] = torch.linspace(0, 1, generation_length)\n",
    "#cond_seq[:, 0] = torch.FloatTensor(multi_linspace([(0,1),(.2,1), (.8,0), (1,0)], generation_length))\n",
    "\n",
    "# amplitude\n",
    "#cond_seq[:, 1] = .9\n",
    "#cond_seq[:, 1] = torch.FloatTensor(multi_linspace([(0,1),(.5,1), (1,1)], generation_length))\n",
    "#cond_seq[:, 1] = torch.FloatTensor(multi_linspace([(0,1),(.5,1), (1,1)], generation_length))\n",
    "cond_seq[:, 1] = torch.FloatTensor(multi_linspace([(0,.8),(1/8-.03,.25), (1/8,.25), (1/8, .8), (2/8-.03, .25), (2/8, .25),(2/8, .8), (3/8-.03, .25), (3/8, .25),(3/8, .8), (4/8-.03, .25), (4/8, .25),(4/8, .8), (5/8-.03, .25), (5/8, .25), (5/8, .8), (6/8-.03, .25), (6/8, .25), (6/8, .8), (7/8-.03, .25), (7/8, .25), (7/8, .8), (1-.03, .8), (1, .8), (1,.8)], generation_length))\n",
    "\n",
    "# pitch\n",
    "#cond_seq[:, 2] = 4/12\n",
    "cond_seq[:, 2] = torch.FloatTensor(steps(np.array([0,2,4,5,7,9,11,12])/12., generation_length))\n",
    "#cond_seq[:, 2] = torch.FloatTensor(steps(np.array([12,11,9,7,5,4,2,0])/12., generation_length))\n",
    "#cond_seq[:, 2] = torch.FloatTensor(steps(np.array([12,11,10, 11, 12, 12 ,12])/12., generation_length))\n",
    "#cond_seq[:, 2] = torch.linspace(0, 1, generation_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973aecca-bd53-4dce-a3f6-b06147fb64a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For nsynth.64.76_sm, the parameter \n",
    "#  Param1 - instID\n",
    "#  Param2 - a (amplitude)\n",
    "#  Param3 - p (pitch in [0,1], representing midi [64, 76]\n",
    "\n",
    "plot_condition_tensor(cond_seq, 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54634131-0c27-4a04-bea3-ba8f567afdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_len = 64\n",
    "t = torch.linspace(0., 1., warmup_len)\n",
    "warmup_sequence = torch.sin(2 * np.pi * 220.0 * t)*.2 # low level\n",
    "\n",
    "start_time = time.monotonic()\n",
    "generated_audio = run_inference(\n",
    "    model=model,\n",
    "    cond_seq=cond_seq,\n",
    "    warmup_sequence=warmup_sequence,\n",
    "    top_n=top_n,\n",
    "    temperature=temperature\n",
    ")\n",
    "elapsed_time = time.monotonic() - start_time\n",
    "print(f\"Time to generate: {elapsed_time:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9a68c3-de88-48b9-be3a-2ae8ac3e7c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"Saving waveform plot to {args.output_plot_path}\")\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(generated_audio)\n",
    "plt.title(\"Generated Audio Waveform\")\n",
    "plt.xlabel(\"Sample\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.grid()\n",
    "#plt.savefig(args.output_plot_path)\n",
    "#plt.close()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acce1224-3131-4522-b72f-a1c9d6f4a588",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(generated_audio, rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dab6c9-9a8a-4f68-99fa-cadb7aa5db18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------  pitch glide  --------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a555443-d586-42da-bdb0-524a5daa1201",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cond_seq = torch.zeros(generation_length, num_cond_params)\n",
    "\n",
    "# instID\n",
    "cond_seq[:, 0] = 0  # 0 - clarinet, 1 - trumpet\n",
    "# amplitude\n",
    "cond_seq[:, 1] = .6\n",
    "# pitch\n",
    "cond_seq[:, 2] = torch.linspace(0, 1, generation_length)\n",
    "\n",
    "plot_condition_tensor(cond_seq, 16000)\n",
    "\n",
    "generated_audio_glide = run_inference(\n",
    "    model=model,\n",
    "    cond_seq=cond_seq,\n",
    "    warmup_sequence=warmup_sequence,\n",
    "    top_n=top_n,\n",
    "    temperature=temperature\n",
    ")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(generated_audio_glide)\n",
    "plt.title(\"Generated Audio Waveform\")\n",
    "plt.xlabel(\"Sample\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.grid()\n",
    "\n",
    "plt.show()\n",
    "Audio(generated_audio_glide, rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9d5cfd-6804-4bea-b4c7-6b34865ba5d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c522bc7-9349-496f-804d-b2fa21a9614b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
